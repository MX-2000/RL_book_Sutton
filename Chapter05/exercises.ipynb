{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.1</b> \n",
    "</p>\n",
    "\n",
    "Consider the diagrams on the right in Figure 5.1. Why does the estimated value function jump up for the last two rows in the rear? Why does it drop off for the whole last row on the left? Why are the frontmost values higher in the upper diagrams\n",
    "than in the lower?\n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value function increases for the last two rows because this is where the player has 20 or 21 and sticks. The probability of the player winning is big in these cases. \n",
    "\n",
    "For the left-most rows, the dealer is being delt an A, the best card possible for the dealer as any figure makes a 21, and its value can be changed to 1 if required. \n",
    "\n",
    "The frontmost values are higher in the upper diagrams than in the lower because having no usable ace means you can't change the value of the ace to one if you go bust. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.2</b> \n",
    "</p>\n",
    "\n",
    "Suppose every-visit MC was used instead of first-visit MC on the blackjack task. Would you expect the results to be very different? Why or why not? \n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think the results would be very different because the same state doesn't gets visited twice in a blackjack episode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.3</b> \n",
    "</p>\n",
    "\n",
    "What is the backup diagram for Monte Carlo estimation of $q_{\\pi}$? \n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>\n",
    "\n",
    "It would look exactly the same as the one for $v_{\\pi}$ with the difference that a $q_{\\pi}(s_t,a_t)$ at a given time $t$ would be represented by the combination of white and black circle instead of a single white circle for $v_{\\pi}(s_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.4</b> \n",
    "</p>\n",
    "\n",
    "The pseudocode for Monte Carlo ES is inecient because, for each state–\n",
    "action pair, it maintains a list of all returns and repeatedly calculates their mean. It would\n",
    "be more ecient to use techniques similar to those explained in Section 2.4 to maintain\n",
    "just the mean and a count (for each state–action pair) and update them incrementally.\n",
    "Describe how the pseudocode would be altered to achieve this.\n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of keeping a list of returns for each state-action pair, we could keep a tuple of the current average estimate and the number of time this state-action pair has been visited. \n",
    "\n",
    "We then update: \n",
    "\n",
    "$Q(S_t,A_t) \\leftarrow Q(S_t,A_t) + \\frac{1}{N(S_t,A_t)}[G-Q(S_t,A_t)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.5</b> \n",
    "</p>\n",
    "\n",
    "Consider an MDP with a single nonterminal state and a single action that transitions back to the nonterminal state with probability $p$ and transitions to the terminal state with probability $1-p$. Let the reward be +1 on all transitions, and let $\\gamma= 1$. Suppose you observe one episode that lasts 10 steps, with a return of 10. What are the first-visit and every-visit estimators of the value of the nonterminal state?\n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first visit case, we take the average of the estimated return G on the first time step only, meaning the estimate is: \n",
    "\n",
    "$\\sum_{k=0}^{T-1}\\gamma^{k}R_{k+1} = \\sum_{k=1}^{T}R_k = 10$ because $\\gamma=1$\n",
    "\n",
    "In the case of every visit, we need to average all the returns G in every timestep because we are in the same state action pair at every time step in this example. The estimated value would then be: \n",
    "\n",
    "$mean([1,2,3,4,5,6,7,8,9,10]) =  5.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.6</b> \n",
    "</p>\n",
    "\n",
    "What is the equation analogous to (5.6) for action values $Q(s, a)$ instead of state values $V(s)$, again given returns generated using b?\n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Q(s,a) \\doteq \\frac{\\sum_{t \\in \\mathbb{J}(s,a)}\\rho_{t:\\mathbb{T}(t)-1}G_t}{\\sum_{t \\in \\mathbb{J}(s,a)}\\rho_{t:\\mathbb{T}(t)-1}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.7</b> \n",
    "</p>\n",
    "\n",
    "In learning curves such as those shown in Figure 5.3 error generally decreases\n",
    "with training, as indeed happened for the ordinary importance-sampling method. But for\n",
    "the weighted importance-sampling method error first increased and then decreased. Why\n",
    "do you think this happened?\n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted importance sampling is biased towards $V_b(s)$ at first, therefore we might see a spike in the first episodes before converging back to $V_{\\pi}(s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:25px;\">\n",
    "<b>Exercise 5.8</b> \n",
    "</p>\n",
    "\n",
    "The results with Example 5.5 and shown in Figure 5.4 used a first-visit MC method. Suppose that instead an every-visit MC method was used on the same problem. Would the variance of the estimator still be infinite? Why or why not? \n",
    "\n",
    "<p style=\"font-size:22px;\">\n",
    "<b>Answer:</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
